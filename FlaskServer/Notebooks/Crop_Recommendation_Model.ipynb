{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/usman619/Downloads/FlaskServer/processed_dataset/crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph    rainfall label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>107</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>26.774637</td>\n",
       "      <td>66.413269</td>\n",
       "      <td>6.780064</td>\n",
       "      <td>177.774507</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>27.417112</td>\n",
       "      <td>56.636362</td>\n",
       "      <td>6.086922</td>\n",
       "      <td>127.924610</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>118</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>24.131797</td>\n",
       "      <td>67.225123</td>\n",
       "      <td>6.362608</td>\n",
       "      <td>173.322839</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>117</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>26.272418</td>\n",
       "      <td>52.127394</td>\n",
       "      <td>6.758793</td>\n",
       "      <td>127.175293</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>104</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>23.603016</td>\n",
       "      <td>60.396475</td>\n",
       "      <td>6.779833</td>\n",
       "      <td>140.937041</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N   P   K  temperature   humidity        ph    rainfall   label\n",
       "2195  107  34  32    26.774637  66.413269  6.780064  177.774507  coffee\n",
       "2196   99  15  27    27.417112  56.636362  6.086922  127.924610  coffee\n",
       "2197  118  33  30    24.131797  67.225123  6.362608  173.322839  coffee\n",
       "2198  117  32  34    26.272418  52.127394  6.758793  127.175293  coffee\n",
       "2199  104  18  30    23.603016  60.396475  6.779833  140.937041  coffee"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
       "       'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
       "       'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
       "       'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N                int64\n",
       "P                int64\n",
       "K                int64\n",
       "temperature    float64\n",
       "humidity       float64\n",
       "ph             float64\n",
       "rainfall       float64\n",
       "label           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "rice           100\n",
       "maize          100\n",
       "jute           100\n",
       "cotton         100\n",
       "coconut        100\n",
       "papaya         100\n",
       "orange         100\n",
       "apple          100\n",
       "muskmelon      100\n",
       "watermelon     100\n",
       "grapes         100\n",
       "mango          100\n",
       "banana         100\n",
       "pomegranate    100\n",
       "lentil         100\n",
       "blackgram      100\n",
       "mungbean       100\n",
       "mothbeans      100\n",
       "pigeonpeas     100\n",
       "kidneybeans    100\n",
       "chickpea       100\n",
       "coffee         100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'rice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/usman619/Downloads/FlaskServer/Notebooks/Crop_Recommendation_Model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/usman619/Downloads/FlaskServer/Notebooks/Crop_Recommendation_Model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sns\u001b[39m.\u001b[39mheatmap(df\u001b[39m.\u001b[39;49mcorr(),annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10704\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10702\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m  10703\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m> 10704\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m  10706\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10707\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1887\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1888\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1889\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1890\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1891\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1656\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1657\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1713\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1714\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1715\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1716\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1718\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'rice'"
     ]
    }
   ],
   "source": [
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating features and target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\n",
    "target = df['label']\n",
    "#features = df[['temperature', 'humidity', 'ph', 'rainfall']]\n",
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialzing empty lists to append all model's name and corresponding name\n",
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy is:  90.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        13\n",
      "      banana       1.00      1.00      1.00        17\n",
      "   blackgram       0.59      1.00      0.74        16\n",
      "    chickpea       1.00      1.00      1.00        21\n",
      "     coconut       0.91      1.00      0.95        21\n",
      "      coffee       1.00      1.00      1.00        22\n",
      "      cotton       1.00      1.00      1.00        20\n",
      "      grapes       1.00      1.00      1.00        18\n",
      "        jute       0.74      0.93      0.83        28\n",
      " kidneybeans       0.00      0.00      0.00        14\n",
      "      lentil       0.68      1.00      0.81        23\n",
      "       maize       1.00      1.00      1.00        21\n",
      "       mango       1.00      1.00      1.00        26\n",
      "   mothbeans       0.00      0.00      0.00        19\n",
      "    mungbean       1.00      1.00      1.00        24\n",
      "   muskmelon       1.00      1.00      1.00        23\n",
      "      orange       1.00      1.00      1.00        29\n",
      "      papaya       1.00      0.84      0.91        19\n",
      "  pigeonpeas       0.62      1.00      0.77        18\n",
      " pomegranate       1.00      1.00      1.00        17\n",
      "        rice       1.00      0.62      0.77        16\n",
      "  watermelon       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.90       440\n",
      "   macro avg       0.84      0.88      0.85       440\n",
      "weighted avg       0.86      0.90      0.87       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DecisionTree = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n",
    "\n",
    "DecisionTree.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = DecisionTree.predict(Xtest)\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Decision Tree')\n",
    "print(\"DecisionTrees's Accuracy is: \", x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (Decision Tree)\n",
    "score = cross_val_score(DecisionTree, features, target,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93636364, 0.90909091, 0.91818182, 0.87045455, 0.93636364])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "DT_pkl_filename = '/home/usman619/Downloads/FlaskServer/models/DecisionTree.pkl'\n",
    "# Open the file to save as pkl file\n",
    "DT_Model_pkl = open(DT_pkl_filename, 'wb')\n",
    "pickle.dump(DecisionTree, DT_Model_pkl)\n",
    "# Close the pickle instances\n",
    "DT_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes's Accuracy is:  0.990909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        13\n",
      "      banana       1.00      1.00      1.00        17\n",
      "   blackgram       1.00      1.00      1.00        16\n",
      "    chickpea       1.00      1.00      1.00        21\n",
      "     coconut       1.00      1.00      1.00        21\n",
      "      coffee       1.00      1.00      1.00        22\n",
      "      cotton       1.00      1.00      1.00        20\n",
      "      grapes       1.00      1.00      1.00        18\n",
      "        jute       0.88      1.00      0.93        28\n",
      " kidneybeans       1.00      1.00      1.00        14\n",
      "      lentil       1.00      1.00      1.00        23\n",
      "       maize       1.00      1.00      1.00        21\n",
      "       mango       1.00      1.00      1.00        26\n",
      "   mothbeans       1.00      1.00      1.00        19\n",
      "    mungbean       1.00      1.00      1.00        24\n",
      "   muskmelon       1.00      1.00      1.00        23\n",
      "      orange       1.00      1.00      1.00        29\n",
      "      papaya       1.00      1.00      1.00        19\n",
      "  pigeonpeas       1.00      1.00      1.00        18\n",
      " pomegranate       1.00      1.00      1.00        17\n",
      "        rice       1.00      0.75      0.86        16\n",
      "  watermelon       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NaiveBayes = GaussianNB()\n",
    "\n",
    "NaiveBayes.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = NaiveBayes.predict(Xtest)\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Naive Bayes')\n",
    "print(\"Naive Bayes's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99772727, 0.99545455, 0.99545455, 0.99545455, 0.99090909])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (NaiveBayes)\n",
    "score = cross_val_score(NaiveBayes,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Guassian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "NB_pkl_filename = '../models/NBClassifier.pkl'\n",
    "# Open the file to save as pkl file\n",
    "NB_Model_pkl = open(NB_pkl_filename, 'wb')\n",
    "pickle.dump(NaiveBayes, NB_Model_pkl)\n",
    "# Close the pickle instances\n",
    "NB_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's Accuracy is:  0.9795454545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        13\n",
      "      banana       1.00      1.00      1.00        17\n",
      "   blackgram       1.00      1.00      1.00        16\n",
      "    chickpea       1.00      1.00      1.00        21\n",
      "     coconut       1.00      1.00      1.00        21\n",
      "      coffee       1.00      0.95      0.98        22\n",
      "      cotton       0.95      1.00      0.98        20\n",
      "      grapes       1.00      1.00      1.00        18\n",
      "        jute       0.83      0.89      0.86        28\n",
      " kidneybeans       1.00      1.00      1.00        14\n",
      "      lentil       1.00      1.00      1.00        23\n",
      "       maize       1.00      0.95      0.98        21\n",
      "       mango       1.00      1.00      1.00        26\n",
      "   mothbeans       1.00      1.00      1.00        19\n",
      "    mungbean       1.00      1.00      1.00        24\n",
      "   muskmelon       1.00      1.00      1.00        23\n",
      "      orange       1.00      1.00      1.00        29\n",
      "      papaya       1.00      1.00      1.00        19\n",
      "  pigeonpeas       1.00      1.00      1.00        18\n",
      " pomegranate       1.00      1.00      1.00        17\n",
      "        rice       0.80      0.75      0.77        16\n",
      "  watermelon       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.98       440\n",
      "   macro avg       0.98      0.98      0.98       440\n",
      "weighted avg       0.98      0.98      0.98       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(Xtrain)\n",
    "X_train_norm = norm.transform(Xtrain)\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(Xtest)\n",
    "SVM = SVC(kernel='poly', degree=3, C=1)\n",
    "SVM.fit(X_train_norm,Ytrain)\n",
    "predicted_values = SVM.predict(X_test_norm)\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('SVM')\n",
    "print(\"SVM's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97954545, 0.975     , 0.98863636, 0.98863636, 0.98181818])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (SVM)\n",
    "score = cross_val_score(SVM,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving trained SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained SVM classifier with Pickle\n",
    "SVM_pkl_filename = '../models/SVMClassifier.pkl'\n",
    "# Open the file to save as pkl file\n",
    "SVM_Model_pkl = open(SVM_pkl_filename, 'wb')\n",
    "pickle.dump(SVM, SVM_Model_pkl)\n",
    "# Close the pickle instances\n",
    "SVM_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression's Accuracy is:  0.9522727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        13\n",
      "      banana       1.00      1.00      1.00        17\n",
      "   blackgram       0.86      0.75      0.80        16\n",
      "    chickpea       1.00      1.00      1.00        21\n",
      "     coconut       1.00      1.00      1.00        21\n",
      "      coffee       1.00      1.00      1.00        22\n",
      "      cotton       0.86      0.90      0.88        20\n",
      "      grapes       1.00      1.00      1.00        18\n",
      "        jute       0.84      0.93      0.88        28\n",
      " kidneybeans       1.00      1.00      1.00        14\n",
      "      lentil       0.88      1.00      0.94        23\n",
      "       maize       0.90      0.86      0.88        21\n",
      "       mango       0.96      1.00      0.98        26\n",
      "   mothbeans       0.84      0.84      0.84        19\n",
      "    mungbean       1.00      0.96      0.98        24\n",
      "   muskmelon       1.00      1.00      1.00        23\n",
      "      orange       1.00      1.00      1.00        29\n",
      "      papaya       1.00      0.95      0.97        19\n",
      "  pigeonpeas       1.00      1.00      1.00        18\n",
      " pomegranate       1.00      1.00      1.00        17\n",
      "        rice       0.85      0.69      0.76        16\n",
      "  watermelon       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.95       440\n",
      "   macro avg       0.95      0.95      0.95       440\n",
      "weighted avg       0.95      0.95      0.95       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression(random_state=2)\n",
    "\n",
    "LogReg.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = LogReg.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Logistic Regression')\n",
    "print(\"Logistic Regression's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95      , 0.96590909, 0.94772727, 0.96590909, 0.94318182])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (Logistic Regression)\n",
    "score = cross_val_score(LogReg,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "LR_pkl_filename = '../models/LogisticRegression.pkl'\n",
    "# Open the file to save as pkl file\n",
    "LR_Model_pkl = open(DT_pkl_filename, 'wb')\n",
    "pickle.dump(LogReg, LR_Model_pkl)\n",
    "# Close the pickle instances\n",
    "LR_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF's Accuracy is:  0.990909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        13\n",
      "      banana       1.00      1.00      1.00        17\n",
      "   blackgram       0.94      1.00      0.97        16\n",
      "    chickpea       1.00      1.00      1.00        21\n",
      "     coconut       1.00      1.00      1.00        21\n",
      "      coffee       1.00      1.00      1.00        22\n",
      "      cotton       1.00      1.00      1.00        20\n",
      "      grapes       1.00      1.00      1.00        18\n",
      "        jute       0.90      1.00      0.95        28\n",
      " kidneybeans       1.00      1.00      1.00        14\n",
      "      lentil       1.00      1.00      1.00        23\n",
      "       maize       1.00      1.00      1.00        21\n",
      "       mango       1.00      1.00      1.00        26\n",
      "   mothbeans       1.00      0.95      0.97        19\n",
      "    mungbean       1.00      1.00      1.00        24\n",
      "   muskmelon       1.00      1.00      1.00        23\n",
      "      orange       1.00      1.00      1.00        29\n",
      "      papaya       1.00      1.00      1.00        19\n",
      "  pigeonpeas       1.00      1.00      1.00        18\n",
      " pomegranate       1.00      1.00      1.00        17\n",
      "        rice       1.00      0.81      0.90        16\n",
      "  watermelon       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "RF.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = RF.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('RF')\n",
    "print(\"RF's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99772727, 0.99545455, 0.99772727, 0.99318182, 0.98863636])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (Random Forest)\n",
    "score = cross_val_score(RF,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "RF_pkl_filename = '../models/RandomForest.pkl'\n",
    "# Open the file to save as pkl file\n",
    "RF_Model_pkl = open(RF_pkl_filename, 'wb')\n",
    "pickle.dump(RF, RF_Model_pkl)\n",
    "# Close the pickle instances\n",
    "RF_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost's Accuracy is:  0.9931818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        13\n",
      "      banana       1.00      1.00      1.00        17\n",
      "   blackgram       1.00      1.00      1.00        16\n",
      "    chickpea       1.00      1.00      1.00        21\n",
      "     coconut       1.00      1.00      1.00        21\n",
      "      coffee       0.96      1.00      0.98        22\n",
      "      cotton       1.00      1.00      1.00        20\n",
      "      grapes       1.00      1.00      1.00        18\n",
      "        jute       1.00      0.93      0.96        28\n",
      " kidneybeans       1.00      1.00      1.00        14\n",
      "      lentil       0.96      1.00      0.98        23\n",
      "       maize       1.00      1.00      1.00        21\n",
      "       mango       1.00      1.00      1.00        26\n",
      "   mothbeans       1.00      0.95      0.97        19\n",
      "    mungbean       1.00      1.00      1.00        24\n",
      "   muskmelon       1.00      1.00      1.00        23\n",
      "      orange       1.00      1.00      1.00        29\n",
      "      papaya       1.00      1.00      1.00        19\n",
      "  pigeonpeas       1.00      1.00      1.00        18\n",
      " pomegranate       1.00      1.00      1.00        17\n",
      "        rice       0.94      1.00      0.97        16\n",
      "  watermelon       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "XB = xgb.XGBClassifier()\n",
    "XB.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = XB.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('XGBoost')\n",
    "print(\"XGBoost's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:54:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99318182, 0.99318182, 0.99318182, 0.99090909, 0.99090909])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (XGBoost)\n",
    "score = cross_val_score(XB,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "XB_pkl_filename = '../models/XGBoost.pkl'\n",
    "# Open the file to save as pkl file\n",
    "XB_Model_pkl = open(XB_pkl_filename, 'wb')\n",
    "pickle.dump(XB, XB_Model_pkl)\n",
    "# Close the pickle instances\n",
    "XB_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Accuracy Comparison'}, xlabel='Accuracy', ylabel='Algorithm'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5],dpi = 100)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Algorithm')\n",
    "sns.barplot(x = acc,y = model,palette='dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree --> 0.9\n",
      "Naive Bayes --> 0.990909090909091\n",
      "SVM --> 0.9795454545454545\n",
      "Logistic Regression --> 0.9522727272727273\n",
      "RF --> 0.990909090909091\n",
      "XGBoost --> 0.9931818181818182\n"
     ]
    }
   ],
   "source": [
    "accuracy_models = dict(zip(model, acc))\n",
    "for k, v in accuracy_models.items():\n",
    "    print (k, '-->', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coffee']\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jute']\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
